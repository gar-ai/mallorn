{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mallorn: Edge Model Delta Updates\n",
    "\n",
    "This notebook demonstrates the complete workflow for creating and applying model patches using Mallorn.\n",
    "\n",
    "**Key Benefits:**\n",
    "- 95%+ bandwidth reduction for OTA updates\n",
    "- ~10ms fingerprinting for version detection\n",
    "- Ed25519 signing for security"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install mallorn if not already installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install mallorn\n",
    "import mallorn\n",
    "print(f\"Mallorn version: {mallorn.__doc__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Sample Models\n",
    "\n",
    "For demonstration, we'll create two synthetic \"models\" (in practice, these would be TFLite, GGUF, or ONNX files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Create temporary directory for our files\n",
    "tmpdir = tempfile.mkdtemp(prefix=\"mallorn_demo_\")\n",
    "\n",
    "# Simulate a model file (16 MB of weights)\n",
    "np.random.seed(42)\n",
    "model_v1_weights = np.random.randn(4 * 1024 * 1024).astype(np.float32)\n",
    "\n",
    "# V2 is a \"fine-tuned\" version (small changes)\n",
    "model_v2_weights = model_v1_weights.copy()\n",
    "# Simulate fine-tuning: small adjustments to 10% of weights\n",
    "mask = np.random.random(len(model_v2_weights)) < 0.1\n",
    "model_v2_weights[mask] += np.random.randn(mask.sum()).astype(np.float32) * 0.01\n",
    "\n",
    "# Save as raw binary (in practice, use TFLite/GGUF/ONNX)\n",
    "v1_path = os.path.join(tmpdir, \"model_v1.bin\")\n",
    "v2_path = os.path.join(tmpdir, \"model_v2.bin\")\n",
    "patch_path = os.path.join(tmpdir, \"update.patch\")\n",
    "\n",
    "model_v1_weights.tofile(v1_path)\n",
    "model_v2_weights.tofile(v2_path)\n",
    "\n",
    "print(f\"Model V1: {os.path.getsize(v1_path):,} bytes\")\n",
    "print(f\"Model V2: {os.path.getsize(v2_path):,} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Fingerprinting\n",
    "\n",
    "Before updating, we need to identify which version a device has. Fingerprinting is fast (~10ms) regardless of model size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Fingerprint both models\n",
    "start = time.time()\n",
    "fp_v1 = mallorn.fingerprint(v1_path)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"V1 Fingerprint:\")\n",
    "print(f\"  Size: {fp_v1.file_size:,} bytes\")\n",
    "print(f\"  Short ID: {fp_v1.short()}\")\n",
    "print(f\"  Time: {elapsed*1000:.2f}ms\")\n",
    "\n",
    "fp_v2 = mallorn.fingerprint(v2_path)\n",
    "print(f\"\\nV2 Fingerprint:\")\n",
    "print(f\"  Size: {fp_v2.file_size:,} bytes\")\n",
    "print(f\"  Short ID: {fp_v2.short()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare fingerprints\n",
    "if mallorn.compare_fingerprints(v1_path, v2_path):\n",
    "    print(\"Models are the same version\")\n",
    "else:\n",
    "    print(\"Models are different - update needed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create a Patch\n",
    "\n",
    "Create a delta patch from V1 to V2. This captures only the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create patch with neural-aware compression (best for fine-tuned models)\n",
    "stats = mallorn.create_patch(\n",
    "    v1_path,\n",
    "    v2_path,\n",
    "    patch_path,\n",
    "    compression_level=9,\n",
    "    neural=True\n",
    ")\n",
    "\n",
    "print(f\"Patch Statistics:\")\n",
    "print(f\"  Source size: {stats.source_size:,} bytes\")\n",
    "print(f\"  Target size: {stats.target_size:,} bytes\")\n",
    "print(f\"  Patch size:  {stats.patch_size:,} bytes\")\n",
    "print(f\"  Compression: {stats.compression_ratio:.1f}x\")\n",
    "print(f\"  Bandwidth savings: {(1 - stats.patch_size / stats.target_size) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. View Patch Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = mallorn.patch_info(patch_path)\n",
    "\n",
    "print(f\"Patch Details:\")\n",
    "print(f\"  Format: {info.format}\")\n",
    "print(f\"  Version: {info.version}\")\n",
    "print(f\"  Source hash: {info.source_hash[:16]}...\")\n",
    "print(f\"  Target hash: {info.target_hash[:16]}...\")\n",
    "print(f\"  Compression: {info.compression}\")\n",
    "print(f\"  Operations: {info.operation_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Apply the Patch\n",
    "\n",
    "Simulate what happens on the device: apply the patch to V1 to get V2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restored_path = os.path.join(tmpdir, \"model_v2_restored.bin\")\n",
    "\n",
    "result = mallorn.apply_patch(v1_path, patch_path, restored_path)\n",
    "\n",
    "print(f\"Patch Application Result:\")\n",
    "print(f\"  Source valid: {result.source_valid}\")\n",
    "print(f\"  Patch valid: {result.patch_valid}\")\n",
    "print(f\"  Overall: {'SUCCESS' if result.is_valid() else 'FAILED'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the restored model matches the original V2\n",
    "import hashlib\n",
    "\n",
    "def file_hash(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return hashlib.sha256(f.read()).hexdigest()[:16]\n",
    "\n",
    "original_hash = file_hash(v2_path)\n",
    "restored_hash = file_hash(restored_path)\n",
    "\n",
    "print(f\"Original V2 hash:  {original_hash}\")\n",
    "print(f\"Restored V2 hash:  {restored_hash}\")\n",
    "print(f\"Match: {'YES' if original_hash == restored_hash else 'NO'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Verify Before Applying\n",
    "\n",
    "On resource-constrained devices, verify the patch can be applied before committing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification without applying\n",
    "verify_result = mallorn.verify_patch(v1_path, patch_path)\n",
    "\n",
    "print(f\"Verification:\")\n",
    "print(f\"  Source matches: {verify_result.source_valid}\")\n",
    "print(f\"  Patch integrity: {verify_result.patch_valid}\")\n",
    "print(f\"  Expected output hash: {verify_result.expected_target_hash[:16]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(tmpdir)\n",
    "print(f\"Cleaned up {tmpdir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Operation | Function | Typical Time |\n",
    "|-----------|----------|-------------|\n",
    "| Fingerprint | `mallorn.fingerprint()` | ~10ms |\n",
    "| Compare | `mallorn.compare_fingerprints()` | ~20ms |\n",
    "| Create Patch | `mallorn.create_patch()` | ~1-10s |\n",
    "| Apply Patch | `mallorn.apply_patch()` | ~0.5-5s |\n",
    "| Verify | `mallorn.verify_patch()` | ~100ms |\n",
    "\n",
    "Typical bandwidth savings: **90-99%** for fine-tuned models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
